<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Malware Classification</title>

  <!-- Bootstrap core CSS -->
  <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark static-top">
    <div class="container">
      <a class="navbar-brand" href="../home.html">Practical Machine Deep Learning</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="../home.html">Home
              <span class="sr-only">(current)</span>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../contact.html">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h1 class="mt-5">Malware Classification</h1>
        <ul class="list-unstyled">
          <li>Mariam Abul-Ela</li>
          <li>Nada Badawy </li>
        </ul>
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Problem Statement</h2>
		<p>
			Our goal is to perform a multi-class classification of malware to classify different 25 Family of Malware. Malware, which is short for malicious software, is a blanket term for viruses, trojans and other harmful computer programs that hackers use to wreak destruction and gain access to sensitive information. These types of malware can damage the system, so they need to be detected. One way to predict the new attacks is to be able to differentiate between the different Malware families. Predicting the right family enables us to efficiently deal with the threat.
		</p>
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Dataset</h2>

        <p>
          We mainly used the Malimg Dataset which contains 9339 malware images, belonging to 25 families/classes. Thus, our goal is to perform a multi-class classification of malware. We choose to use Malimg dataset because our baseline model is good at classifying images because it can extract relevant features within an image by subsampling through convolutions, pooling, and other computation techniques. The advantage of the malimg dataset is that the malware images are PE files that were first converted to an 8-bit vector binary, and then to images. Thus, we will use the grayscale images directly without first converting them. The following table summarize the 25 classes which we will use. 
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Dataset.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Input/Output Examples</h2>

        <p>
          Here is an example of a grey scale input image which holds the data for the PE file for specific malware class. The model should output the name of the right class.
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/IN_OUT.PNG" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">State of the art</h2>

        <p>
          State of the art

          Malware classification has many deep neural network models that solve this issue. Based on our research, we found four models that works with image classification. We examined three of them to solve our main problem malware classification.
          <br/>  <br/>Model one: CNN-SVM [1]the convolutional neural network CNN usually uses the softmax activation function as top layer for prediction and cross-entorpy loss function. But, according to one of the research papers, they use linear support vector machine SVM instead of softmax activation function. This is because they found that objective of SVM is to find the optimal hyperplane f (w, x) = w Â· x + b to separate two classes in a given dataset which is advantage for its usage. SVM. Hence, using CNN-SVM will enhance the accuracy of CNN model. This model reach accuracy of 77% using Malimg dataset.
          <br/>  <br/>Model two: GRU-SVM [2]model. GRU is based on RNN model which is enhanced version of LSTM and using SoftMax as final output layer and cross-entroby function to compute the losses. Yet, in GRU-SVM the parameters get learned through GRU and SVM works as activation function in a neural network architecture instead of softmax. This model reached 84% of accuracy using Malimg dataset.  
          <br/>  <br/>Model three: VGG16 [3]model which is a version of CNN model. VGG16 contains 16 deep neural network layers including 3 by 3 convolution filters. 13 of the layers are convolutional layers each three followed by Maxpooling layer. Then two fully connected layers and the output layer. This model achieved 92% accuracy in ImageNet dataset which is a dataset of over 14 million images belonging to 1000 classes.
          <br/>  <br/>Model four: Transformer[4] is a model that uses attention to increase the model speed. Specifically, it uses self-attention. It contains six encoder and six decoders. Each encoder has two layers: self-attention and a feed Forward Neural Network. Also, the decoder has the same layers but between then there is an attention layer. This attention layer helps the decoder focusing on the relevant parts of the input image. Transformers have advantage over the RNN because it solves the problem of parallelization, by utilizing CNN together with attention model. This model archive accuracy of 88.55% in ImageNet dataset.
          
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Stat.PNG" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Orignial Model from Literature </h2>

        <p>
          After the research we made, we decided to use VGG16 as our main model. It is pretrained model on ImageNet dataset Fig(1). To be able to train our data set we fine tuning the last layer as in Fig(2).   
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/st1.PNG" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->

      <br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/st2.PNG" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>

    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Proposed Updates</h2>

    
		<h5 class="mt-5">Update #1: Add GRU</h5>
		<p>
			Then we add layer of the GRU as classifier and softmax activation function Fig(3).
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/update1.jpeg" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->

		<h5 class="mt-5">Update #2: ADD SVM</h5>
		<p>
			In this phase we decided to replace the softmax activation function with SVM. To add the SVM, it requires to add hinge loss as activation function with L2 regulaizar Fig(4).
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/update2.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5">Results</h2>

      <p>
          We performed a variety of experiments, on both the augmented and the original dataset. Here, we present results for 6 separate experiments, as listed in Table [2]. In the remainder of this section, we discuss each of these experiments in some detail and present the results of each.
		</p>

		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/R.PNG" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>
    <h5 class="mt-5">VGG16-GRU-SVM</h5>
		<p>
			Our first proposed architecture was the VGG16-GRU-SVM. Table [2] shows the detailed hyperparameters used to train the model. The results show low accuracy of 2%. These results made us to try other variations.
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/VGG16-GRU-SVM.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      
    <h5 class="mt-5">GRU-SVM</h5>
		<p>
			When we did not get good results on our proposed model (VGG16-GRU-SVM), we tried to divide it into small parts and test each part alone. So, one of these parts was the GRU-SVM. We Trained and tested the model against the hyperparameters found in table [2]. Furthermore, as shown in the results we did not get any better results.
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/GRU-SVM.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      
    <h5 class="mt-5">VGG16</h5>
		<p>
			The second part was the VGG16, so we train and test it. The results show 66% validation accuracy. 
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/VGG16.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
     

    <h5 class="mt-5">VGG16-GRU</h5>
		<p>
			After many triers we concluded and decided that we will not include the SVM in our Model and instead we will use Softmax. 
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/VGG16-GRU.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
     
    <h5 class="mt-5">Deep GRU</h5>
		<p>
			We trained our final model for 100 epochs over 11130 Malware grayscale image and tested it with 4470 samples. The model was trained to classify 25 different class of malware. The validation accuracy of the model reached 98.7% and the validation loss of 0.0915. moreover, the Confusion Matrix shows a good predictive accuracy for each malware family. However, Swizzor.gen!E and Swizzor.gen!I shows relatively low presession, recall and f1 score but in overall, all families shows high low precession, recall and f1 score 
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Deep GRU.png" class="img-fluid text-center">
          <img src="resources/images/Deep GRU3.png" class="img-fluid text-center">
          <img src="resources/images/Deep GRU2.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
     

    <h5 class="mt-5">Transformer</h5>
		<p>
			We tried the transformer to decide if we will change the deep GRU with the transformer or not. we trained it with 100 epochs and get the validation accuracy 91.68.
		</p>
		<br/> <!-- Empty Line before the image -->
	    <div class="img-container" align="center"> <!-- Block parent element -->
      		<img src="resources/images/Transformer 1.png" class="img-fluid text-center">
          <img src="resources/images/Transformer 3.png" class="img-fluid text-center">
          <img src="resources/images/transformer2.png" class="img-fluid text-center">
    	</div>
    	<br/> <!-- Empty Line after the image -->
      </div>
    </div>
    


    <div class="row">
      <div class="col-lg-12 text-left">
        <h2 class="mt-5"> Implementation Details </h2>

        
			
		
       <p>
       
        In this study, Google TensorFlow was used to implement the deep learning algorithms, with the aid of other scientific computing libraries: matplotlib, numpy, and scikit-learn. We conduct the training on python 3.7 environment using Jupiter notebook. The choice of TensorFlow and sklearn was influenced by the fact that they incorporate several DL best practices, including learning rate finding, stochastic gradient descent with restarts, and differential learning rates.
        
       </p>
		  
	
      </div>
    </div>

	<div class="row">
	  <div class="col-lg-12 text-left">
	    <h2 class="mt-5">Conclusion</h2>

	    <p>
        We used the Malimg dataset [5], which consists of malware images for the purpose of malware family classification. We trained 6 models on 11130 Malware grayscale image and tested them with 4470 samples. The empirical data shows that the deep GRU model had the highest predictive accuracy among VGG16-GRU-SVM, GRU-SVM, VGG16, VGG16-GRU, and the transformer, having a test accuracy of 98.7%. 
        Improving the architecture design of the transformer model by adding more  layers, adding better nonlinearities, and/or using an optimized dropout, may provide better insights on their application on malware classification. Such insights may reveal an information as to which architecture may serve best in the engineering of an intelligent anti-malware system. 
        
		</p>

	  </div>
	</div>

	<div class="row">
	  <div class="col-lg-12 text-left">
	    <h2 class="mt-5">References</h2>

	    

		<ol>
		  <li><a href="https://arxiv.org/pdf/1712.03541v2.pdf">[1]Agarap, A. (2019, February 7). An Architecture Combining Convolutional Neural Network (CNN) and Support Vector Machine (SVM) for Image</a></li>
		  
		  <li><a href="https://paperswithcode.com/paper/a-neural-network-architecture-combining-gated#code ">[2] Agarap, A. (2019, September 10). A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data. Retrieved from</a></li>
      
      <li><a href="https://www.researchgate.net/publication/319952138_Deep_Convolutional_Neural_Networks_with_transfer_learning_for_computer_vision-based_data-driven_pavement_distress_detection">[3] Gopalakrishnan, Kasthurirangan & Khaitan, S.K. & Choudhary, Alok & Agrawal, Ankit. (2017). Deep Convolutional Neural Networks with transfer learning for computer vision-based data-driven pavement distress detection. Construction and Building Materials. 157. 322-330. 10.1016/j.conbuildmat.2017.09.110. </a></li>
      
      <li><a href="https://towardsdatascience.com/transformers-141e32e69591">[4] G Giacaglia, G. (2020, October 5). How Transformers Work - Towards Data Science. Medium. https://towardsdatascience.com/transformers-141e32e69591 iacaglia, G. (2020, October 5). How Transformers Work - Towards Data Science. Medium. </a></li>
      
      <li><a href="https://sarvamblog.blogspot.com/2014/08/supervised-classification-with-k-fold.html">[5]Dataset URL</a></li>
		</ol> 
	  </div>
	</div>

  </div>



  <!-- Bootstrap core JavaScript -->
  <script src="../vendor/jquery/jquery.slim.min.js"></script>
  <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>

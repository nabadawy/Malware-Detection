{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "FinalVGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUVoWxvT5ZRU"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "from numpy.random import randn\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pathlib\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.activations import sigmoid, softmax\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60EeY51B5ZRZ"
      },
      "source": [
        "!git clone -b new https://github.com/nabadawy/Malware-Detection.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMsaR5H5ZRa"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "data_dir = pathlib.Path('Malware-Detection1/malimg_paper_dataset_imgs')\n",
        "\n",
        "\n",
        "label_names={'Adialer.C': 0, 'Agent.FYI': 1, 'Allaple.A': 2, 'Allaple.L': 3, 'Alueron.gen!J': 4, 'Autorun.K':5,'C2LOP.gen!g':6,'C2LOP.P':7,\n",
        "             'Dialplatform.B':8,'Dontovo.A':9,'Fakerean':10,'Instantaccess':11,'Lolyda.AA1':12,'Lolyda.AA2':13,'Lolyda.AA3':14,'Lolyda.AT':15,\n",
        "             'Malex.gen!J':16,'Obfuscator.AD':17,'Rbot!gen':18,'Skintrim.N':19,'Swizzor.gen!E':20,'Swizzor.gen!I':21,'VB.AT':22,'Wintrim.BX':23,\n",
        "             'Yuner.A':24}\n",
        "label_key=['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K','C2LOP.gen!g','C2LOP.P',\n",
        "             'Dialplatform.B','Dontovo.A','Fakerean','Instantaccess','Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT',\n",
        "             'Malex.gen!J','Obfuscator.AD','Rbot!gen','Skintrim.N','Swizzor.gen!E','Swizzor.gen!I','VB.AT','Wintrim.BX',\n",
        "             'Yuner.A']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-69jrqZ5ZRb"
      },
      "source": [
        "all_images = list(data_dir.glob('*/*'))\n",
        "all_images = [str(path) for path in all_images]\n",
        "random.shuffle(all_images)\n",
        "\n",
        "all_labels=[label_names[pathlib.Path(path).parent.name] for path in all_images]\n",
        "\n",
        "data_size=len(all_images)\n",
        "\n",
        "train_test_split=(int)(data_size*0.1)\n",
        "\n",
        "img_train=all_images[train_test_split:]\n",
        "img_test=all_images[:train_test_split]\n",
        "\n",
        "lable_train=all_labels[train_test_split:]\n",
        "lable_test=all_labels[:train_test_split]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6i42wEd5ZRc"
      },
      "source": [
        "IMG_SIZE=224\n",
        "\n",
        "def _parse_data(x,y):\n",
        "  image = tf.io.read_file(x)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        " \n",
        "  return image,y\n",
        "\n",
        "def _input_fn(x,y):\n",
        "  ds=tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  ds=ds.map(_parse_data)\n",
        "  ds=ds.shuffle(buffer_size=data_size)\n",
        "\n",
        "  ds = ds.repeat()\n",
        "  \n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  \n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  \n",
        "  return ds\n",
        "  \n",
        "train_ds=_input_fn(img_train,lable_train)\n",
        "validation_ds=_input_fn(img_test, lable_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Bb1pDS5ZRd"
      },
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "VGG16_MODEL=tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "VGG16_MODEL.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL28Sg8_5ZRe"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  VGG16_MODEL,\n",
        "   tf.keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
        "   tf.keras.layers.Dense(28,kernel_regularizer= tf.keras.regularizers.l2(0.01), bias_regularizer= tf.keras.regularizers.l2(0.01), activation=tf.nn.relu),\n",
        "   tf.keras.layers.Dense(10,kernel_regularizer= tf.keras.regularizers.l2(0.01), bias_regularizer= tf.keras.regularizers.l2(0.01), activation=tf.nn.relu),\n",
        "   tf.keras.layers.Dense(len(label_names),kernel_regularizer= tf.keras.regularizers.l1_l2(0.01), bias_regularizer=tf.keras.regularizers.l1_l2(0.01),activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adagrad(learning_rate=0.001), \n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqzLrWVf5ZRf"
      },
      "source": [
        "BATCH_SIZE = 200\n",
        "EPOCHS = 45\n",
        "callback=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "VGG16_his = model.fit(\n",
        "                    train_ds,\n",
        "                    epochs= EPOCHS,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    steps_per_epoch=2,\n",
        "                    validation_steps=2,\n",
        "                    validation_data=validation_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lvgrt7T5ZRf"
      },
      "source": [
        "\n",
        "validation_steps = 20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_ds, steps = validation_steps)\n",
        "\n",
        "print(\"loss: {:.2f}\".format(loss0))\n",
        "print(\"accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "training_acc = VGG16_his.history['accuracy']\n",
        "val_acc = VGG16_his.history['val_accuracy']\n",
        "epoch_count = range(1, EPOCHS + 1)\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count,  val_acc, 'b-')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('VGG16 Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['VGG16 training accuracy', 'VGG16 Val accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}